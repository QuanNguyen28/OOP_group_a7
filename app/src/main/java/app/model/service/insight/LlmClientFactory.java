package app.model.service.insight;

public final class LlmClientFactory {

    private LlmClientFactory() {}

    public static LlmClient fromFixedDefault() {
        String provider = LlmSettings.PROVIDER == null ? "mock" : LlmSettings.PROVIDER.trim().toLowerCase();
        switch (provider) {
            case "gemini":
                return new GeminiClient(LlmSettings.API_KEY, LlmSettings.MODEL, LlmSettings.BASE_URL);
            // Báº¡n cÃ³ thá»ƒ thÃªm OpenAIClient/OllamaClient náº¿u cáº§n:
            // case "openai": return new OpenAIClient(LlmSettings.API_KEY, LlmSettings.MODEL, LlmSettings.BASE_URL);
            // case "ollama": return new OllamaClient(LlmSettings.MODEL, LlmSettings.BASE_URL);
            default:
                return new MockLlmClient(); // fallback an toÃ n khi chÆ°a cáº¥u hÃ¬nh
        }
    }

    /** Mock tá»‘i giáº£n Ä‘á»ƒ dev/test offline. */
    static class MockLlmClient implements LlmClient {
        @Override public String complete(String prompt) {
            // rÃºt gá»n 1-2 cÃ¢u tá»« prompt, trÃ¡nh gá»i máº¡ng
            String p = prompt == null ? "" : prompt.trim();
            if (p.length() > 600) p = p.substring(0, 600) + "...";
            return "ğŸ“ (Mock summary)\n" + p;
        }
    }
}